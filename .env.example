# ================== Environment Variables Example File ==================
# Usage:
# 1. Copy this file as `.env.local`
# 2. Update the values according to your local / deployment environment
# 3. Make sure `.env.local` is added to .gitignore and NEVER committed to version control

# ========== GitHub Configuration ==========
# [Sensitive] GitHub access token, used to access the GitHub API (do NOT expose or commit this value)
# Common usage:
# - Generate a Classic Token or Fine-grained Token in your GitHub settings
# - Only enable the minimal scopes required by this project (e.g. repo, read:org)
GITHUB_ACCESS_TOKEN="YOUR_GITHUB_ACCESS_TOKEN_HERE"

# ========== Application Data Mode Configuration ==========
# Frontend data mode, controls how the application fetches data
# Actual behavior:
# - When the value is "mock": the frontend uses local mock data and does NOT call the real backend API
# - When it is any other value (including an empty string ""): the frontend calls the real backend API
# Recommendations:
# - When developing / integrating with a real backend: leave this as an empty string "" (default behavior, calls real backend)
# - When you want a pure frontend demo or have no backend environment: set this to "mock"
NEXT_PUBLIC_DATA_MODE=""

# ========== AI Service Base Configuration ==========
# Base URL of the AI HTTP endpoint, must be compatible with the OpenAI API protocol
# Common examples:
# - OpenAI official: https://api.openai.com/v1
# - DeepSeek:        https://api.deepseek.com/v1
# - Tongyi Qianwen (proxy example): https://dashscope.aliyuncs.com/compatible-mode/v1
AI_BASE_URL=""

# [Sensitive] AI service API key, used for authentication when calling the AI API (do NOT expose or commit this value)
# How to obtain:
# - Log in to the corresponding AI service console and create a key in the API Key / Access Key section
# - Restrict permissions and quota based on actual needs to reduce potential abuse
AI_API_KEY="YOUR_AI_API_KEY_HERE"

# ========== AI Model Configuration ==========
# Default model name to use; it must exactly match a model supported by the selected AI service
# Common examples:
# - OpenAI:   gpt-4o-mini, gpt-4.1-mini, gpt-4.1
# - DeepSeek: deepseek-chat, deepseek-reasoner
# - Other compatible providers: please refer to their official model list documentation
AI_MODEL=""

